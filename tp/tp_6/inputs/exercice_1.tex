\chapter{RNN simple pour Arduino}

\section{But de l'exercice}
Le but de l'exercice est de simuler un réseau de neurones récurrents (\textbf{RNN}) pour \textbf{prédire} une séquence de sortie en fonction d'une séquence d'entrée. 
Le \textbf{RNN} est composé de trois couches de neurones: une couche d'entrée, une couche cachée et une
couche de sortie. Les poids et les biais de chaque couche sont initialisés aléatoirement à l'aide
de la fonction d'initialisation des poids. Les sorties sont calculés par l'algorithme de
\textbf{``propagation avant''} de l'entrée à travers le réseau pour calculer la sortie en utilisant la fonction
d'activation \textbf{sigmoid}. Le seuil de prédiction de sortie est donné par la valeur lu du d'une
fonction \textbf{valpot} et ajuste le seuil de prédiction en conséquence. La prédiction est initialisé par
la séquence d'entrée avec des valeurs aléatoires et démarre la séquence de prédiction. Dans
la boucle \textbf{loop()}, la séquence d'entrée est avancée à chaque itération et la séquence de sortie
est prédite. La valeur prédite est affichée sur la \textbf{LED interne} de l'arduino Due en fonction du
seuil de prédiction. \\

Le code de cet exercice est fourni en annexe. \hyperref[sec:RNN-code]{Code de l'exercice}.
\section{Réponse à l'exercice}
\begin{enumerate}
  \item {
    \textbf{Quel est le rôle de la fonction initializeWeights?} \vspace{0.2cm}\\
    Le rôle de la fonction initializeWeights est d'intialiser les valeurs des poids et des biais contenues 
    dans les différentes matrices \textbf{weightsIH}, \textbf{weightsHH}, \textbf{weightsHO}, \textbf{biasH} et \textbf{biasO}. 
    Les valeurs utilisées pour initialiser les différentes valeurs sont des valeurs aléatoires comprises entre 0 et 1.
  } \\
  \item {
    \textbf{Comment est calculé l'état caché (hidden state) dans la fonction forwardPass?} \vspace{0.2cm}\\
    La fonction \textbf{forwardPass} calcule l'état caché en effectuant une série d'opérations de calculs sur les entrées fournies
    dans le tableau d'entrées ainsi que sur les différents biais et poids du réseaux stockés globalement. \\
    Plus précisément, la fonction calcule l'état caché en effectuant les opérations suivantes:
    \begin{enumerate}
      \item Initialiser les valeurs de l'état caché à 0.
      \item Pour chaque neurone d'entrée, multiplier la valeur de l'entrée correspondante par le poids correspondant entre l'entrée et le neurone caché.
      \item Pour chaque neurone caché, multiplier la valeur de son état actuel par le poids correspondant entre ce neurone et le neurone caché considéré.
      \item Ajouter la somme de ces produits pondérés à la valeur du biais du neurone caché considéré.
      \item Appliquer une fonction d'activation à la somme pondérée obtenue pour obtenir la valeur finale de l'état caché pour le neurone considéré.
    \end{enumerate}
    Ces étapes sont effectuées pour chaque neurone caché dans le réseau, ce qui permet de calculer l'état caché complet du réseau de neurones.
  } \\
  \item {
    \textbf{Quel est l'avantage de l'utilisation de la fonction d'activation sigmoid pour calculer les sorties du réseau de neurones?}\vspace{0.2cm}\\
    Les avantages de l'utilisation de la fonction \textbf{sigmoïd} en tant que fonction d'activation est qu'elle possède une plage de sortie entre 0 et 1, ce 
    qui est particulièrement adapté pour des problèmes de classification binaire, notre cas d'étude nécéssite une sortie binaire 0 ou 1 pour l'état de la LED.\@
  } \\
  \item {
    \textbf{A quoi sert la fonction readPoten et comment est-elle utilisée pour ajuster le seuil de prédiction?} \vspace{0.2cm}\\
    La fonction \textbf{readPoten} permet de lire la valeur du potentiomètre. Par la suite elle map cette valeur entre 0 et 1 et set le treshold à cette valeur.\\
    Le treshold permet de considérer si un output est une valeur positive ou négative. Dans notre cas positive représente allumer la LED et négative représente éteindre la LED.\@
  } \\
  \item {
    \textbf{A quoi sert la fonction startPrediction et comment est-elle utilisée pour calculer la prédiction?} \vspace{0.2cm}\\
    La fonction startPrediction initialise les valeurs du tableau d'entrée entre 0 et 1. Par la suite, elle met la valeur de la variable \textbf{predict} à la valeur \textbf{true}.
    Cette valeur de la variable \textbf{predict} permet d'indiquer à la boucle \textbf{loop} du programme de commencer la prédiction du réseau sur le tableau d'entrée.\\
    En résumé cette fonction possède à la fois un rôle d'initialisation mais également d'initiatrice du réseau de neurone.
  } \\
  \item {
    \textbf{Expliquer comment le RNN calcule la sortie avec la fonction forwardPass et comment on peut faire pour étendre le nombre des cellules RNN?} \vspace{0.2cm}\\
    Le \textbf{RNN} utilise la fonction \textbf{forwardPass} pour calculer la \textbf{sortie} du réseau en focntion de \textbf{l'état caché} et des \textbf{entrées}. Cette fonction 
    prend en entrée un \textbf{tableau d'entrée}, un \textbf{tableau de sortie} et un \textbf{tableau d'état caché}. La fonction calcule l'\textbf{état caché} en utilisant les \textbf{entrées} et l'état \textbf{caché}
    de la couche précédente, en utilisant les \textbf{poids} et les \textbf{biais}, puis passe cette somme pondérée à une \textbf{fonction d'activation} pour obtenir l'état caché de la cellule. Ceci est répété pour chaque 
    cellule de la couche cachée. \\
    Ensuite la fonction \textbf{forwardPass} calcule la séquence de sortie en bouclant sur les \textbf{cellules de sortie} du \textbf{RNN}. Pour chaque cellule de sortie, la fonction calcule la \textbf{somme pondérée} des états
    cachés de toutes les cellules RNN en utilisant les \textbf{poids weightsHO} et le biais \textbf{biasO}. Cette somme pondérée est ensuite passée à la fonction d'activation pour \textbf{obtenir la sortie} de la cellule.
  
    Pour étendre le nombre de \textbf{cellules RNN} dans le réseau, il faut ajouter des cellules RNN supplémentaires à la couche cachée. Cela implique d'augmenter la taille des tableaux \textbf{hidden}, \textbf{weightsHH}.
    Il faut également modifier la fonction \textbf{forwardPass} pour prendre en compte ces nouvelles cellules.
  }
\end{enumerate}